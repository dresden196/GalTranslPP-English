module;

#ifdef _WIN32
#include <Windows.h>
#include <Shlwapi.h>
#pragma comment(lib, "Shlwapi.lib")
#endif

#define PYBIND11_HEADERS
#include "GPPMacros.hpp"
#include <spdlog/spdlog.h>
#include <unicode/regex.h>
#include <unicode/unistr.h>
#include <toml.hpp>
#include <ctpl_stl.h>
#include <sol/sol.hpp>

export module NormalJsonTranslator;

import APIPool;
import ConditionTool;
import Dictionary;
import DictionaryGenerator;
import IPlugin;
import ProblemAnalyzer;
import NJ_ImplTool;
import NLPTool;
import LuaManager;
import PythonManager;
export import ITranslator;

using json = nlohmann::json;
using ordered_json = nlohmann::ordered_json;
namespace py = pybind11;
namespace fs = std::filesystem;

export {

    class NormalJsonTranslator : public ITranslator {
    public:

        TransEngine m_transEngine;
        std::shared_ptr<IController> m_controller;
        std::shared_ptr<spdlog::logger> m_logger;

        fs::path m_inputDir;
        fs::path m_inputCacheDir;
        fs::path m_outputDir;
        fs::path m_outputCacheDir;
        fs::path m_cacheDir;
        fs::path m_projectDir;

        std::string m_systemPrompt;
        std::string m_userPrompt;
        std::string m_targetLang;

        int m_totalSentences = 0;
        std::atomic<int> m_completedSentences = 0;
        std::atomic<long long> m_pluginTimeUsed = 0;

        int m_threadsNum;
        int m_batchSize;
        int m_contextHistorySize;
        int m_maxRetries;
        int m_saveCacheInterval;
        int m_apiTimeOutMs;
        bool m_pythonTranslator = false;
        bool m_checkQuota;
        bool m_smartRetry;
        bool m_usePreDictInName;
        bool m_usePostDictInName;
        bool m_usePreDictInMsg;
        bool m_usePostDictInMsg;
        bool m_useGptDictToReplaceName;
        bool m_outputWithSrc;

        std::string m_apiStrategy;
        std::string m_sortMethod;
        std::string m_splitFile;
        int m_splitFileNum;
        std::string m_linebreakSymbol;
        std::vector<CheckSeCondFunc> m_retranslKeys;
        // first: 要忽略的 problem 正则表达式 pattern，second: 忽略条件
        using SkipProblemCondition = std::pair<std::shared_ptr<icu::RegexPattern>, std::optional<CheckSeCondFunc>>;
        std::vector<SkipProblemCondition> m_skipProblems;

        PythonManager m_pythonManager;
        LuaManager m_luaManager;

        bool m_needsCombining = false;
        // 输入分割文件相对路径到原始json相对路径的映射
        std::map<fs::path, fs::path> m_splitFilePartsToJson;
        // 原始json相对路径到多个输入分割文件相对路径及其有没有完成的映射
        std::map<fs::path, std::map<fs::path, bool>> m_jsonToSplitFileParts;

        std::map<std::string, std::string> m_nameMap;
        toml::ordered_value m_problemOverview = toml::array{};
        std::function<void(fs::path)> m_onFileProcessed;
        std::shared_mutex m_cacheMutex;
        std::mutex m_outputMutex;

        ctpl::thread_pool m_threadPool{1};
        APIPool m_apiPool;
        GptDictionary m_gptDictionary;
        NormalDictionary m_preDictionary;
        NormalDictionary m_postDictionary;
        ProblemAnalyzer m_problemAnalyzer;
        std::function<NLPResult(const std::string&)> m_tokenizeSourceLangFunc;
        std::vector<pro::proxy<PPlugin>> m_prePlugins;
        std::vector<pro::proxy<PPlugin>> m_postPlugins;


        void preProcess(Sentence* se);

        void postProcess(Sentence* se);

        bool translateBatchWithRetry(const fs::path& relInputPath, std::vector<Sentence*>& batch, int threadId);

        void processFile(const fs::path& relInputPath, int threadId);

    public:
        NormalJsonTranslator(const fs::path& projectDir, std::shared_ptr<IController> controller, std::shared_ptr<spdlog::logger> logger,
            std::optional<fs::path> inputDir = std::nullopt, std::optional<fs::path> inputCacheDir = std::nullopt,
            std::optional<fs::path> outputDir = std::nullopt, std::optional<fs::path> outputCacheDir = std::nullopt);

        virtual ~NormalJsonTranslator() override
        {
            m_logger->info("所有任务已完成！NormalJsonTranslator结束。");
        }

        void init();
        std::optional<std::vector<fs::path>> beforeRun();
        void process(std::vector<fs::path> relFilePaths);
        void afterRun();

        virtual void run() override;
    };
}

module :private;

NormalJsonTranslator::NormalJsonTranslator(const fs::path& projectDir, std::shared_ptr<IController> controller, std::shared_ptr<spdlog::logger> logger,
    std::optional<fs::path> inputDir, std::optional<fs::path> inputCacheDir,
    std::optional<fs::path> outputDir, std::optional<fs::path> outputCacheDir) :
    m_projectDir(projectDir), m_controller(controller), m_logger(logger), m_luaManager(logger), m_pythonManager(logger),
    m_apiPool(logger), m_gptDictionary(logger), m_preDictionary(logger), m_postDictionary(logger), m_problemAnalyzer(logger)
{
    m_logger->info("GalTransl++ NormalJsonTranslator 启动...");
    m_inputDir = inputDir.value_or(m_projectDir / L"gt_input");
    m_inputCacheDir = inputCacheDir.value_or(L"cache" / m_projectDir.filename() / L"gt_input_cache");
    m_outputDir = outputDir.value_or(m_projectDir / L"gt_output");
    m_outputCacheDir = outputCacheDir.value_or(L"cache" / m_projectDir.filename() / L"gt_output_cache");
    m_cacheDir = m_projectDir / L"transl_cache";
}

void NormalJsonTranslator::init()
{
    fs::path configPath = m_projectDir / L"config.toml";
    if (!fs::exists(configPath)) {
        throw std::runtime_error("找不到 config.toml 文件");
    }
    try {
        bool needReboot = false;
        const auto configData = toml::parse(configPath);
        
        const std::string& transEngineStr = toml::find_or(configData, "plugins", "transEngine", "ForGalJson");
        if (transEngineStr == "ForGalJson") {
            m_transEngine = TransEngine::ForGalJson;
        }
        else if (transEngineStr == "ForGalTsv") {
            m_transEngine = TransEngine::ForGalTsv;
        }
        else if (transEngineStr == "ForNovelTsv") {
            m_transEngine = TransEngine::ForNovelTsv;
        }
        else if (transEngineStr == "DeepseekJson") {
            m_transEngine = TransEngine::DeepseekJson;
        }
        else if (transEngineStr == "Sakura") {
            m_transEngine = TransEngine::Sakura;
        }
        else if (transEngineStr == "DumpName") {
            m_transEngine = TransEngine::DumpName;
        }
        else if (transEngineStr == "GenDict") {
            m_transEngine = TransEngine::GenDict;
        }
        else if (transEngineStr == "Rebuild") {
            m_transEngine = TransEngine::Rebuild;
        }
        else if (transEngineStr == "ShowNormal") {
            m_transEngine = TransEngine::ShowNormal;
        }
        else {
            throw std::runtime_error("Invalid trans engine");
        }


        m_apiStrategy = toml::find_or(configData, "backendSpecific", "OpenAI-Compatible", "apiStrategy", "random");
        if (m_apiStrategy != "random" && m_apiStrategy != "fallback") {
            throw std::invalid_argument("apiStrategy must be random or fallback in config.toml");
        }
        int apiTimeOutSecond = toml::find_or(configData, "backendSpecific", "OpenAI-Compatible", "apiTimeout", 120);
        m_apiTimeOutMs = apiTimeOutSecond * 1000;

        // 需要API
        if (m_transEngine != TransEngine::DumpName && m_transEngine != TransEngine::Rebuild && m_transEngine != TransEngine::ShowNormal) {
            const auto& apisArr = toml::find<
                std::vector<toml::table>
            >(configData, "backendSpecific", "OpenAI-Compatible", "apis");

            std::vector<TranslationApi> apis;
            for (const auto& apiTbl : apisArr) {
                TranslationApi api;
                if (apiTbl.contains("apikey") && !apiTbl.at("apikey").as_string().empty()) {
                    api.apikey = apiTbl.at("apikey").as_string();
                }
                else if (m_transEngine == TransEngine::Sakura) {
                    api.apikey = "sk-sakura";
                }
                else {
                    continue;
                }
                if (apiTbl.contains("apiurl") && !apiTbl.at("apiurl").as_string().empty()) {
                    api.apiurl = cvt2StdApiUrl(apiTbl.at("apiurl").as_string());
                }
                else {
                    continue;
                }
                if (apiTbl.contains("modelName") && !apiTbl.at("modelName").as_string().empty()) {
                    api.modelName = apiTbl.at("modelName").as_string();
                }
                else if (m_transEngine == TransEngine::Sakura) {
                    api.modelName = "sakura";
                }
                else {
                    continue;
                }
                api.stream = apiTbl.contains("stream") && apiTbl.at("stream").as_boolean();
                apis.push_back(std::move(api));
            }

            if (apis.empty()) {
                throw std::invalid_argument("config.toml 中找不到可用的 apikey ");
            }
            else {
                m_apiPool.loadAPIs(std::move(apis));
            }
        }

        const auto pluginConfigData = toml::parse(pluginConfigsPath / L"filePlugins/NormalJson.toml");
        m_outputWithSrc = parseToml<bool>(configData, pluginConfigData, "plugins.NormalJson.output_with_src");

        m_batchSize = toml::find_or(configData, "common", "numPerRequestTranslate", 8);
        m_threadsNum = toml::find_or(configData, "common", "threadsNum", 1);
        m_sortMethod = toml::find_or(configData, "common", "sortMethod", "name");
        m_targetLang = toml::find_or(configData, "common", "targetLang", "zh-cn");
        m_splitFile = toml::find_or(configData, "common", "splitFile", "no");
        m_splitFileNum = toml::find_or(configData, "common", "splitFileNum", 25);
        m_saveCacheInterval = toml::find_or(configData, "common", "saveCacheInterval", 1);
        m_linebreakSymbol = toml::find_or(configData, "common", "linebreakSymbol", "auto");
        m_maxRetries = toml::find_or(configData, "common", "maxRetries", 5);
        m_contextHistorySize = toml::find_or(configData, "common", "contextHistorySize", 8);
        m_smartRetry = toml::find_or(configData, "common", "smartRetry", true);
        m_checkQuota = toml::find_or(configData, "common", "checkQuota", true);

        // 需要 tokenizeSourceLangFunc
        if (m_transEngine != TransEngine::DumpName) {
            const std::string& tokenizerBackend = toml::find_or(configData, "common", "tokenizerBackend", "MeCab");

            if (tokenizerBackend == "MeCab") {
                const std::string& mecabDictDir = toml::find_or(configData, "common", "mecabDictDir", "BaseConfig/mecabDict/mecab-ipadic-utf8");
                m_logger->info("正在检查 MeCab 环境...");
                m_tokenizeSourceLangFunc = getMeCabTokenizeFunc(mecabDictDir, m_logger);
                m_logger->info("MeCab 环境检查完毕。");
            }
            else if (tokenizerBackend == "spaCy") {
                const std::string& spaCyModelName = toml::find_or(configData, "common", "spaCyModelName", "ja_core_news_sm");
                m_logger->info("正在检查 spaCy 环境...");
                m_tokenizeSourceLangFunc = getNLPTokenizeFunc({ "spacy" }, "tokenizer_spacy", spaCyModelName, m_logger, needReboot);
                m_logger->info("spaCy 环境检查完毕。");
            }
            else if (tokenizerBackend == "Stanza") {
                const std::string& stanzaLang = toml::find_or(configData, "common", "stanzaLang", "zh");
                m_logger->info("正在检查 Stanza 环境...");
                m_tokenizeSourceLangFunc = getNLPTokenizeFunc({ "stanza" }, "tokenizer_stanza", stanzaLang, m_logger, needReboot);
                m_logger->info("Stanza 环境检查完毕。");
            }
            else {
                throw std::invalid_argument("无效的 tokenizerBackend: " + tokenizerBackend);
            }
            m_gptDictionary.setTokenizeSourceLangFunc(m_tokenizeSourceLangFunc);
        }

        // 需要预处理
        if (m_transEngine != TransEngine::DumpName) {
            const auto& textPrePlugins = toml::find<
                std::optional<std::vector<std::string>>
            >(configData, "plugins", "textPrePlugins");
            if (textPrePlugins) {
                m_prePlugins = registerPlugins(*textPrePlugins, m_projectDir, m_pythonManager, m_luaManager, m_logger, configData);
            }
        }

        // 需要后处理
        if (m_transEngine != TransEngine::DumpName && m_transEngine != TransEngine::ShowNormal && m_transEngine != TransEngine::GenDict) {
            const auto& textPostPlugins = toml::find<
                std::optional<std::vector<std::string>>
            >(configData, "plugins", "textPostPlugins");
            if (textPostPlugins) {
                m_postPlugins = registerPlugins(*textPostPlugins, m_projectDir, m_pythonManager, m_luaManager, m_logger, configData);
            }
        }

        const auto& problemList = toml::find<
            std::optional<std::vector<std::string>>
        >(configData, "problemAnalyze", "problemList");
        if (problemList) {
            const std::string& punctSet = toml::find_or(configData, "problemAnalyze", "punctSet", "（()）：:*[]{}<>『』「」“”;；'/\\");
            const std::string& codePage = toml::find_or(configData, "problemAnalyze", "codePage", "gbk");
            double langProbability = toml::find_or(configData, "problemAnalyze", "langProbability", 0.94);
            m_problemAnalyzer.loadProblems(*problemList, punctSet, codePage, langProbability);
        }

        const auto& retranslKeys = toml::find<std::optional<toml::array>>(configData, "problemAnalyze", "retranslKeys");
        if (retranslKeys) {
            for (const auto& elem : *retranslKeys) {
                if (elem.is_string()) {
                    GppConditionPattern pattern;
                    pattern.conditionTarget = CachePart::Problems;
                    icu::UnicodeString ustr = icu::UnicodeString::fromUTF8(elem.as_string());
                    UErrorCode status = U_ZERO_ERROR;
                    pattern.conditionReg = std::shared_ptr<icu::RegexPattern>(icu::RegexPattern::compile(ustr, 0, status));
                    if (U_FAILURE(status)) {
                        throw std::runtime_error(std::format("retranslKeys 正则表达式 [{}] 编译失败", elem.as_string()));
                    }
                    GPPCondition cond{ pattern };
                    CheckSeCondFunc checkFunc = [=](const Sentence* se) -> bool
                        {
                            return checkGppCondition(cond, se);
                        };
                    m_retranslKeys.push_back(std::move(checkFunc));
                }
                else if (elem.is_array() || elem.is_table()) {
                    CheckSeCondFunc checkFunc = getCheckSeCondFunc(elem, m_projectDir, m_pythonManager, m_luaManager, m_logger, needReboot);
                    m_retranslKeys.push_back(std::move(checkFunc));
                }
                else {
                    throw std::invalid_argument("retranslKeys 的元素必须是字符串、表或表数组");
                }
            }
        }

        const auto& skipProblems = toml::find<std::optional<toml::array>>(configData, "problemAnalyze", "skipProblems");
        if (skipProblems) {
            auto compileProblemRegexFunc = [](const std::string& patternStr) -> std::shared_ptr<icu::RegexPattern>
                {
                    icu::UnicodeString ustr = icu::UnicodeString::fromUTF8(patternStr);
                    UErrorCode status = U_ZERO_ERROR;
                    std::shared_ptr<icu::RegexPattern> pattern = std::shared_ptr<icu::RegexPattern>(icu::RegexPattern::compile(ustr, 0, status));
                    if (U_FAILURE(status)) {
                        throw std::runtime_error(std::format("skipProblems Problem正则表达式 [{}] 编译失败", patternStr));
                    }
                    return pattern;
                };
            for (const auto& elem : *skipProblems) {
                if (elem.is_string()) {
                    m_skipProblems.push_back({ compileProblemRegexFunc(elem.as_string()), std::nullopt });
                }
                else if (elem.is_array() && elem.size() > 0) {
                    if (!elem[0].is_string()) {
                        throw std::invalid_argument("skipProblems 的内联表数组第一个元素必须是字符串");
                    }
                    std::shared_ptr<icu::RegexPattern> pattern = compileProblemRegexFunc(elem[0].as_string());
                    if (elem.size() == 1) {
                        m_skipProblems.push_back({ pattern, std::nullopt });
                    }
                    else {
                        CheckSeCondFunc checkFunc = getCheckSeCondFunc(elem, m_projectDir, m_pythonManager, m_luaManager, m_logger, needReboot);
                        m_skipProblems.push_back({ pattern, std::move(checkFunc) });
                    }
                }
                else {
                    throw std::invalid_argument("skipProblems 的元素必须是字符串或表数组");
                }
            }
        }

        const auto& overwriteCompareObj = toml::find<std::optional<toml::array>>(configData, "problemAnalyze", "overwriteCompareObj");
        if (overwriteCompareObj) {
            for (const auto& tbl : *overwriteCompareObj) {
                std::string problemKey = toml::find_or(tbl, "problemKey", "");
                if (problemKey.empty()) {
                    continue;
                }
                std::string base = toml::find_or(tbl, "base", "");
                if (base.empty()) {
                    base = "orig_text";
                }
                std::string check = toml::find_or(tbl, "check", "");
                if (check.empty()) {
                    check = "trans_preview";
                }
                m_problemAnalyzer.overwriteCompareObj(problemKey, base, check);
            }
        }

        const std::string& defaultDictFolder = toml::find_or(configData, "dictionary", "defaultDictFolder", "BaseConfig/Dict");
        const fs::path defaultDictFolderPath = ascii2Wide(defaultDictFolder);

        m_usePreDictInName = toml::find_or(configData, "dictionary", "usePreDictInName", false);
        m_usePostDictInName = toml::find_or(configData, "dictionary", "usePostDictInName", false);
        m_usePreDictInMsg = toml::find_or(configData, "dictionary", "usePreDictInMsg", true);
        m_usePostDictInMsg = toml::find_or(configData, "dictionary", "usePostDictInMsg", true);
        m_useGptDictToReplaceName = toml::find_or(configData, "dictionary", "useGPTDictInName", false);

        auto loadDictsFunc = [&]<typename DictType>(const std::string& dictType, DictType& dict)
            {
                const auto& dictFileNames = toml::find<
                    std::optional<std::vector<std::string>>
                >(configData, "dictionary", dictType + "Dict");
                if (!dictFileNames) {
                    return;
                }
                for (const auto& dictFileName : *dictFileNames) {
                    fs::path dictPath = m_projectDir / ascii2Wide(dictFileName);
                    if (fs::exists(dictPath)) {
                        dict.loadFromFile(dictPath, m_projectDir, m_pythonManager, m_luaManager, needReboot);
                        continue;
                    }
                    else {
                        dictPath = defaultDictFolderPath / ascii2Wide(dictType) / ascii2Wide(dictFileName);
                        if (fs::exists(dictPath)) {
                            dict.loadFromFile(dictPath, m_projectDir, m_pythonManager, m_luaManager, needReboot);
                        }
                    }
                }
                dict.sort();
            };

        loadDictsFunc("gpt", m_gptDictionary);
        loadDictsFunc("pre", m_preDictionary);
        loadDictsFunc("post", m_postDictionary);

        // 需要加载提示词
        if (m_transEngine != TransEngine::DumpName && m_transEngine != TransEngine::Rebuild && m_transEngine != TransEngine::ShowNormal) {
            fs::path promptPath = m_projectDir / L"Prompt.toml";
            if (!fs::exists(promptPath)) {
                promptPath = L"BaseConfig/Prompt.toml";
                if (!fs::exists(promptPath)) {
                    throw std::runtime_error("找不到 Prompt.toml 文件");
                }
            }

            const auto promptData = toml::parse(promptPath);

            std::string systemKey;
            std::string userKey;

            switch (m_transEngine) {
            case TransEngine::ForGalJson:
                systemKey = "FORGALJSON_SYSTEM";
                userKey = "FORGALJSON_TRANS_PROMPT_EN";
                break;
            case TransEngine::ForGalTsv:
                systemKey = "FORGALTSV_SYSTEM";
                userKey = "FORGALTSV_TRANS_PROMPT_EN";
                break;
            case TransEngine::ForNovelTsv:
                systemKey = "FORNOVELTSV_SYSTEM";
                userKey = "FORNOVELTSV_TRANS_PROMPT_EN";
                break;
            case TransEngine::DeepseekJson:
                systemKey = "DEEPSEEKJSON_SYSTEM_PROMPT";
                userKey = "DEEPSEEKJSON_TRANS_PROMPT";
                break;
            case TransEngine::Sakura:
                systemKey = "SAKURA_SYSTEM_PROMPT";
                userKey = "SAKURA_TRANS_PROMPT";
                break;
            case TransEngine::GenDict:
                systemKey = "GENDIC_SYSTEM";
                userKey = "GENDIC_PROMPT";
                break;
            default:
                throw std::invalid_argument("未知的 TransEngine");
            }

            if (promptData.contains(systemKey) && promptData.at(systemKey).is_string()) {
                m_systemPrompt = promptData.at(systemKey).as_string();
            }
            else {
                throw std::invalid_argument(std::format("Prompt.toml 中缺少 {} 键", systemKey));
            }
            if (promptData.contains(userKey) && promptData.at(userKey).is_string()) {
                m_userPrompt = promptData.at(userKey).as_string();
            }
            else {
                throw std::invalid_argument(std::format("Prompt.toml 中缺少 {} 键", userKey));
            }
        }

        needReboot = needReboot
            || std::ranges::any_of(m_prePlugins, [](const auto& plugin) { return plugin->needReboot(); })
            || std::ranges::any_of(m_postPlugins, [](const auto& plugin) { return plugin->needReboot(); });
        if (needReboot) {
            throw std::runtime_error("需要重启程序以应用新安装的 Python 模块");
        }
    }
    catch (const toml::exception& e) {
        m_logger->critical("项目配置文件解析失败");
        throw std::runtime_error(e.what());
    }
}

void NormalJsonTranslator::preProcess(Sentence* se) {

    // se->name = se->name;
    // se->names = se->names;
    // 相当于省略了 name_org 这一项，因为最原始人名并不在缓存里输出
    // se->name 实际上相当于 se->name_preproc
    se->pre_processed_text = se->original_text;

    if (se->nameType != NameType::None && m_usePreDictInName) {
        if (se->nameType == NameType::Single) {
            se->name = m_preDictionary.doReplace(se, CachePart::Name);
        }
        else {
            for (auto& name : se->names) {
                se->name = std::move(name);
                name = m_preDictionary.doReplace(se, CachePart::Name);
            }
        }
    }

    if (m_linebreakSymbol == "auto") {
        if (se->pre_processed_text.find("<br>") != std::string::npos) {
            se->originalLinebreak = "<br>";
        }
        else if (se->pre_processed_text.find("\\r\\n") != std::string::npos) {
            se->originalLinebreak = "\\r\\n";
        }
        else if (se->pre_processed_text.find("\\n") != std::string::npos) {
            se->originalLinebreak = "\\n";
        }
        else if (se->pre_processed_text.find("\\r") != std::string::npos) {
            se->originalLinebreak = "\\r";
        }
        else if (se->pre_processed_text.find("\r\n") != std::string::npos) {
            se->originalLinebreak = "\r\n";
        }
        else if (se->pre_processed_text.find("\n") != std::string::npos) {
            se->originalLinebreak = "\n";
        }
        else if (se->pre_processed_text.find("\r") != std::string::npos) {
            se->originalLinebreak = "\r";
        }
        else if (se->pre_processed_text.find("[r][n]") != std::string::npos) {
            se->originalLinebreak = "[r][n]";
        }
        else if (se->pre_processed_text.find("[n]") != std::string::npos) {
            se->originalLinebreak = "[n]";
        }
        else if (se->pre_processed_text.find("[r]") != std::string::npos) {
            se->originalLinebreak = "[r]";
        }
    }
    else {
        se->originalLinebreak = m_linebreakSymbol;
    }
    if (!se->originalLinebreak.empty()) {
        replaceStrInplace(se->pre_processed_text, se->originalLinebreak, "<br>");
    }
    replaceStrInplace(se->pre_processed_text, "\t", "<tab>");
    if (m_usePreDictInMsg) {
        se->pre_processed_text = m_preDictionary.doReplace(se, CachePart::PreprocText);
    }

    std::chrono::steady_clock::time_point start = std::chrono::steady_clock::now();
    for (auto& plugin : m_prePlugins) {
        plugin->run(se);
        if (se->complete) {
            break;
        }
    }
    m_pluginTimeUsed += std::chrono::duration_cast<std::chrono::nanoseconds>(std::chrono::steady_clock::now() - start).count();

}

void NormalJsonTranslator::postProcess(Sentence* se) {

    se->name_preview = se->name;
    se->names_preview = se->names;
    se->translated_preview = se->pre_translated_text;
    se->problems.clear();

    std::chrono::steady_clock::time_point start = std::chrono::steady_clock::now();
    for (auto& plugin : m_postPlugins) {
        plugin->run(se);
    }
    m_pluginTimeUsed += std::chrono::duration_cast<std::chrono::nanoseconds>(std::chrono::steady_clock::now() - start).count();

    if (m_usePostDictInMsg) {
        se->translated_preview = m_postDictionary.doReplace(se, CachePart::TransPreview);
    }
    replaceStrInplace(se->translated_preview, "<tab>", "\t");
    if (!se->originalLinebreak.empty()) {
        replaceStrInplace(se->translated_preview, "<br>", se->originalLinebreak);
    }

    auto replaceName = [&]() -> std::string
        {
            if (m_useGptDictToReplaceName) {
                se->name_preview = m_gptDictionary.doReplace(se, CachePart::NamePreview);
            }
            if (!se->name_preview.empty()) {
                auto it = m_nameMap.find(se->name_preview);
                if (it != m_nameMap.end() && !it->second.empty()) {
                    se->name_preview = it->second;
                }
            }
            if (m_usePostDictInName) {
                se->name_preview = m_postDictionary.doReplace(se, CachePart::NamePreview);
            }
            return se->name_preview;
        };

    if (se->nameType != NameType::None) {
        if (se->nameType == NameType::Single) {
            replaceName();
        }
        else {
            for (auto& name_preivew : se->names_preview) {
                se->name_preview = std::move(name_preivew);
                name_preivew = replaceName();
            }
        }
    }

    if (!se->notAnalyzeProblem) {
        m_problemAnalyzer.analyze(se, m_gptDictionary, m_targetLang);
    }

    
    std::erase_if(se->problems, [&](auto& problem)
        {
            return std::ranges::any_of(m_skipProblems, [&](const SkipProblemCondition& skipProblemCondition)
                {
                    bool problemMatch = checkString(skipProblemCondition.first, problem);
                    if (!skipProblemCondition.second.has_value()) {
                        return problemMatch;
                    }
                    else {
                        auto checkFunc = [&]() -> bool
                            {
                                problem = "Current problem:" + problem;
                                bool result = skipProblemCondition.second.value()(se);
                                problem = problem.substr(16);
                                return result;
                            };
                        return problemMatch && checkFunc();
                    }
                });
        });
}


bool NormalJsonTranslator::translateBatchWithRetry(const fs::path& relInputPath, std::vector<Sentence*>& batch, int threadId) {

    if (batch.empty()) {
        return true;
    }
    for (Sentence* pSentence : batch) {
        if (pSentence->pre_processed_text.empty()) {
            pSentence->complete = true;
            m_completedSentences++;
            m_controller->updateBar(); // 为空不翻译
        }
    }

    int retryCount = 0;
    std::string contextHistory = buildContextHistory(batch, m_transEngine, m_contextHistorySize, 2048 * 3);
    std::string glossary = m_gptDictionary.generatePrompt(batch, m_transEngine);

    while (retryCount < m_maxRetries) {

        if (m_controller->shouldStop()) {
            return false;
        }

        std::vector<Sentence*> batchToTransThisRound;
        for (Sentence* pSentence : batch | std::views::filter([](const Sentence* pSentence) { return !pSentence->complete; })) {
            batchToTransThisRound.push_back(pSentence);
        }
        if (batchToTransThisRound.empty()) {
            return true;
        }

        if (m_smartRetry && retryCount == 2 && batchToTransThisRound.size() > 1) {
            m_logger->warn("[线程 {}] [文件 {}] 开始拆分批次进行重试...", threadId, wide2Ascii(relInputPath));

            size_t mid = batchToTransThisRound.size() / 2;
            std::vector<Sentence*> firstHalf(batchToTransThisRound.begin(), batchToTransThisRound.begin() + mid);
            std::vector<Sentence*> secondHalf(batchToTransThisRound.begin() + mid, batchToTransThisRound.end());

            bool firstOk = translateBatchWithRetry(relInputPath, firstHalf, threadId);
            bool secondOk = translateBatchWithRetry(relInputPath, secondHalf, threadId);

            return firstOk && secondOk;
        }
        else if (m_smartRetry && retryCount == 3) {
            m_logger->warn("[线程 {}] [文件 {}] 清空上下文后再次尝试...", threadId, wide2Ascii(relInputPath));
            contextHistory.clear();
        }


        std::string inputProblems;
        for (const auto& problem : batchToTransThisRound
            | std::views::transform([](const Sentence* pSentence) { return pSentence->problems; })
            | std::views::join) {
            if (inputProblems.find(problem) == std::string::npos) {
                inputProblems += problem + "\n";
            }
        }

        std::string inputBlock;
        std::map<int, Sentence*> id2SentenceMap; // 用于 TSV/JSON 
        fillBlockAndMap(batchToTransThisRound, id2SentenceMap, inputBlock, m_transEngine);

        m_logger->info("[线程 {}] [文件 {}] 开始翻译\nProblems:\n{}\nDict:\n{}\ninputBlock:\n{}", threadId, wide2Ascii(relInputPath), inputProblems, glossary, inputBlock);
        std::string promptReq = m_userPrompt;
        replaceStrInplace(promptReq, "[Problem Description]", inputProblems);
        replaceStrInplace(promptReq, "[Input]", inputBlock);
        replaceStrInplace(promptReq, "[TargetLang]", m_targetLang);
        replaceStrInplace(promptReq, "[Glossary]", glossary);

        json messages = json::array({ {{"role", "system"}, {"content", m_systemPrompt}} });
        if (!contextHistory.empty()) {
            messages.push_back({ {"role", "user"}, {"content", "<input>(...truncated history source texts...)</input><output>\n"} });
            messages.push_back({ {"role", "assistant"}, {"content", contextHistory} });
        }
        messages.push_back({ {"role", "user"}, {"content", promptReq} });

        auto optApi = m_apiStrategy == "random" ? m_apiPool.getApi() : m_apiPool.getFirstApi();
        if (!optApi.has_value()) {
            throw std::runtime_error("没有可用的API Key了");
        }
        const TranslationApi& currentApi = optApi.value();

        json payload = { {"model", currentApi.modelName}, {"messages", messages} };

        ApiResponse response = performApiRequest(payload, currentApi, threadId, m_controller, m_logger, m_apiTimeOutMs);
        /*bool checkResponse(const ApiResponse & response, const TranslationApi & currentAPI, int& retryCount, const std::filesystem::path & relInputPath,
            int threadId, bool m_checkQuota, const std::string & m_apiStrategy, APIPool & m_apiPool, std::shared_ptr<spdlog::logger> m_logger)*/
        if (!checkResponse(
            response, currentApi, retryCount, relInputPath, threadId, m_checkQuota, m_apiStrategy, m_apiPool, m_logger
        )) {
            continue;
        }

        // --- 如果请求成功，则继续解析 ---
        m_logger->info("[线程 {}] [文件 {}] 成功响应，解析结果: \n{}", threadId, wide2Ascii(relInputPath), response.content);
        int parsedCount = 0;
        bool parseError = false;

        parseContent(response.content, batchToTransThisRound, id2SentenceMap, currentApi.modelName, m_transEngine, parseError, parsedCount,
            m_controller, m_completedSentences);

        if (parseError || parsedCount != batchToTransThisRound.size()) {
            retryCount++;
            m_logger->warn("[线程 {}] [文件 {}] 解析失败或不完整 ({} / {}), 进行第 {} 次重试...", threadId, wide2Ascii(relInputPath.filename()), parsedCount, batchToTransThisRound.size(), retryCount);
            continue;
        }

        m_logger->debug("[线程 {}] 批次翻译成功，解析了 {} 句话。", threadId, parsedCount);
        return true;
    }

    m_logger->error("[线程 {}] [文件 {}] 批次翻译在 {} 次重试后彻底失败。", threadId, wide2Ascii(relInputPath.filename()), m_maxRetries);
    for (auto& pSentence : batch | std::views::filter([](const Sentence* pSentence) { return !pSentence->complete; })) {
        pSentence->pre_translated_text = "(Failed to translate)" + pSentence->pre_processed_text;
        pSentence->complete = true;
        m_completedSentences++;
        m_controller->updateBar(); // 失败
    }
    return false;
}


// ============================================        processFile        ========================================
void NormalJsonTranslator::processFile(const fs::path& relInputPath, int threadId) {
    if (m_controller->shouldStop()) {
        return;
    }
    m_logger->debug("[线程 {}] 开始处理文件: {}", threadId, wide2Ascii(relInputPath));
    m_controller->addThreadNum();

    std::ifstream ifs;
    fs::path inputPath = m_needsCombining ? (m_inputCacheDir / relInputPath) : (m_inputDir / relInputPath);
    fs::path outputPath = m_needsCombining ? (m_outputCacheDir / relInputPath) : (m_outputDir / relInputPath);
    fs::path cachePath = m_cacheDir / relInputPath;
    fs::path showNormalPath = m_projectDir / L"gt_show_normal" / relInputPath;
    createParent(outputPath);
    createParent(cachePath);

    std::vector<Sentence> sentences;
    // 解析输入文件
    try {
        ifs.open(inputPath);
        json data = json::parse(ifs);
        ifs.close();
        for (const auto& [index, item] : data | std::views::enumerate) {
            Sentence se;
            se.index = (int)index;
            if (item.contains("name")) {
                se.nameType = NameType::Single;
                se.name = item.value("name", "");
            }
            else if (item.contains("names")) {
                se.nameType = NameType::Multiple;
                se.names = item["names"].get<std::vector<std::string>>();
            }
            se.original_text = item.value("message", "");
            sentences.push_back(std::move(se));
        }
        for (size_t i = 0; i < sentences.size(); ++i) {
            if (i > 0) sentences[i].prev = &sentences[i - 1];
            if (i + 1 < sentences.size()) sentences[i].next = &sentences[i + 1];
        }
        for (auto& se : sentences) {
            preProcess(&se);
        }
    }
    catch (const json::exception& e) {
        throw std::runtime_error(std::format("[线程 {}] [文件 {}] 解析失败: {}", threadId, wide2Ascii(relInputPath), e.what()));
    }
    // 输入文件解析完毕

    // ShowNormal
    if (m_transEngine == TransEngine::ShowNormal) {
        json showNormalJson = json::array();
        for (const auto& se : sentences) {
            json showNormalObj;
            if (se.nameType == NameType::Single) {
                showNormalObj["name"] = se.name;
            }
            else if (se.nameType == NameType::Multiple) {
                showNormalObj["names"] = se.names;
            }
            showNormalObj["original_text"] = se.original_text;
            if (!se.other_info.empty()) {
                showNormalObj["other_info"] = se.other_info;
            }
            showNormalObj["pre_processed_text"] = se.pre_processed_text;
            showNormalJson.push_back(showNormalObj);
            m_completedSentences++;
            m_controller->updateBar(); // ShowNormal
        }
        createParent(showNormalPath);
        std::ofstream ofs(showNormalPath);
        ofs << showNormalJson.dump(2);
        return;
    }
    // ShowNormal结束

    std::vector<Sentence*> toTranslate;

    // 读缓存逻辑
    {
        std::unordered_map<std::string, json> cacheMap;

        auto insertJsonArrToCacheMap = [&](const json& jsonArr)
            {
                for (size_t i = 0; i < jsonArr.size(); ++i) {
                    const auto& item = jsonArr[i];
                    std::string prevText = "None", currentText, nextText = "None";
                    currentText = getNameString(item) + item.value("original_text", "") + item.value("pre_processed_text", "");
                    if (i > 0) {
                        prevText = getNameString(jsonArr[i - 1]) + jsonArr[i - 1].value("original_text", "") + jsonArr[i - 1].value("pre_processed_text", "");
                    }
                    if (i + 1 < jsonArr.size()) {
                        nextText = getNameString(jsonArr[i + 1]) + jsonArr[i + 1].value("original_text", "") + jsonArr[i + 1].value("pre_processed_text", "");
                    }
                    cacheMap.insert(std::make_pair(prevText + currentText + nextText, item));
                }
            };

        auto usePotentialPartFileCacheToInsertCacheMap = [&](const fs::path& potentialCachePath)
            {
                std::shared_lock<std::shared_mutex> lock(m_cacheMutex);
                try {
                    ifs.open(potentialCachePath);
                    json jsonArr = json::parse(ifs);
                    ifs.close();
                    insertJsonArrToCacheMap(jsonArr);
                }
                catch (const json::exception& e) {
                    throw std::runtime_error(std::format("[线程 {}] 缓存文件 {} 解析失败: {}", threadId, wide2Ascii(fs::relative(potentialCachePath, m_cacheDir)), e.what()));
                }
            };

        std::vector<fs::path> cachePaths;

        auto readAllPotentialPartFileCache = [&](const std::wstring& cacheSpec, const fs::path& specParentDir, std::optional<fs::path> additionalCachePath = std::nullopt)
            {
                for (const auto& entry : fs::directory_iterator(specParentDir)) {
                    if (!entry.is_regular_file()) {
                        continue;
                    }
                    if (PathMatchSpecW(entry.path().filename().wstring().c_str(), cacheSpec.c_str())) {
                        cachePaths.push_back(entry.path());
                    }
                }
                if (additionalCachePath.has_value()) {
                    cachePaths.push_back(additionalCachePath.value());
                }
                for (const auto& cp : cachePaths) {
                    usePotentialPartFileCacheToInsertCacheMap(cp);
                }
            };

            if (m_transEngine == TransEngine::Rebuild) {
                if (fs::exists(cachePath)) {
                    cachePaths.push_back(cachePath);
                }
            }
            else if (m_needsCombining) {
                std::optional<fs::path> additionalCachePath = std::nullopt;
                auto it = m_splitFilePartsToJson.find(relInputPath);
                if (it != m_splitFilePartsToJson.end() && fs::exists(m_cacheDir / it->second)) {
                    additionalCachePath = m_cacheDir / it->second;
                }
                // 这个逻辑还挺耗时的，我自己尝试优化结果大败而归
                size_t pos = relInputPath.filename().wstring().rfind(L"_part_");
                std::wstring orgStem = relInputPath.filename().wstring().substr(0, pos);
                std::wstring cacheSpec = orgStem + L"_part_*.json";
                // 分割优先读分割缓存
                readAllPotentialPartFileCache(cacheSpec, m_cacheDir / relInputPath.parent_path(), additionalCachePath);
            }
            else {
                if (fs::exists(cachePath)) {
                    cachePaths.push_back(cachePath);
                }
                std::wstring cacheSpec = relInputPath.stem().wstring() + L"_part_*.json";
                // 非分割优先读整体缓存
                readAllPotentialPartFileCache(cacheSpec, m_cacheDir / relInputPath.parent_path());
            }

            json totalCacheJsonList = json::array();
            for (const auto& cp : cachePaths) {
                std::shared_lock<std::shared_mutex> lock(m_cacheMutex);
                try {
                    ifs.open(cp);
                    json cacheJsonList = json::parse(ifs);
                    ifs.close();
                    totalCacheJsonList.insert(totalCacheJsonList.end(), cacheJsonList.begin(), cacheJsonList.end());
                }
                catch (const json::exception& e) {
                    throw std::runtime_error(std::format("[线程 {}] 缓存文件 {} 解析失败: {}", threadId, wide2Ascii(cp), e.what()));
                }
            }
            insertJsonArrToCacheMap(totalCacheJsonList);


            for (auto& se : sentences) {
                if (se.complete) {
                    m_completedSentences++;
                    m_controller->updateBar(); // 跳过已完成的句子
                    postProcess(&se);
                    continue;
                }
                std::string key = generateCacheKey(&se);
                auto it = cacheMap.find(key);
                if (it == cacheMap.end()) {
                    toTranslate.push_back(&se);
                    continue;
                }
                const auto& item = it->second;
                // 命中缓存了就把 problems 带上
                if (item.contains("problems")) {
                    se.problems = item["problems"].get<std::vector<std::string>>();
                }
                if (m_transEngine != TransEngine::Rebuild && hasRetranslKey(m_retranslKeys, item, &se)) {
                    toTranslate.push_back(&se);
                    continue;
                }
                else {
                    se.pre_translated_text = item.value("pre_translated_text", "");
                    se.translated_by = item.value("translated_by", "");
                    se.complete = true;
                    m_completedSentences++;
                    m_controller->updateBar(); // 命中缓存
                    postProcess(&se);
                }
            }

            m_logger->info("[线程 {}] [文件 {}] 共 {} 句，命中缓存 {} 句，需翻译 {} 句。", threadId, wide2Ascii(relInputPath),
                sentences.size(), sentences.size() - toTranslate.size(), toTranslate.size());

            if (m_transEngine == TransEngine::Rebuild && !toTranslate.empty()) {
                std::string notFoundSentences;
                for (const auto& se : toTranslate) {
                    notFoundSentences += se->original_text + "\n";
                }
                m_logger->critical("[线程 {}] [文件 {}] 有 {} 句未命中缓存，这些句子是: {}", threadId, wide2Ascii(relInputPath), toTranslate.size(), notFoundSentences);
                std::lock_guard<std::shared_mutex> lock(m_cacheMutex);
                saveCache(sentences, cachePath);
                m_controller->reduceThreadNum();
                return;
            }
    }

    if (!toTranslate.empty()) {
        std::unique_ptr<py::gil_scoped_release> release;
        if (m_pythonTranslator) {
            release = std::make_unique<py::gil_scoped_release>();
        }
        int batchCount = 0;
        for (size_t i = 0; i < toTranslate.size(); i += m_batchSize) {
            if (m_controller->shouldStop()) {
                m_controller->reduceThreadNum();
                return;
            }
            std::vector<Sentence*> batch(toTranslate.begin() + i, toTranslate.begin() + std::min(i + m_batchSize, toTranslate.size()));
            translateBatchWithRetry(relInputPath, batch, threadId);
            for (Sentence* se : batch) {
                postProcess(se);
            }
            batchCount++;
            if (batchCount % m_saveCacheInterval == 0) {
                m_logger->debug("[线程 {}] [文件 {}] 达到保存间隔，正在更新缓存文件...", threadId, wide2Ascii(inputPath));
                std::lock_guard<std::shared_mutex> lock(m_cacheMutex);
                saveCache(sentences, cachePath);
            }
        }
    }

    {
        std::lock_guard<std::shared_mutex> lock(m_cacheMutex);
        m_logger->debug("[线程 {}] [文件 {}] 翻译完成，正在进行最终保存...", threadId, wide2Ascii(inputPath));
        saveCache(sentences, cachePath);

        std::string relInputPathStr = wide2Ascii(relInputPath);
        for (const auto& se : sentences) {
            if (se.problems.empty()) {
                continue;
            }
            toml::ordered_table tbl;
            tbl["filename"] = relInputPathStr;
            tbl["index"] = se.index;
            if (se.nameType == NameType::Single) {
                tbl["name"] = se.name;
                tbl["name_preview"] = se.name_preview;
            }
            else if (se.nameType == NameType::Multiple) {
                tbl["names"] = se.names;
                tbl["names_preview"] = se.names_preview;
            }
            tbl["original_text"] = se.original_text;
            if (!se.other_info.empty()) {
                tbl["other_info"] = se.other_info;
            }
            tbl["pre_processed_text"] = se.pre_processed_text;
            tbl["pre_translated_text"] = se.pre_translated_text;
            tbl["problems"] = se.problems;
            tbl["translated_by"] = se.translated_by;
            tbl["translated_preview"] = se.translated_preview;
            m_problemOverview.push_back(tbl);
        }
    }

    ordered_json outputJson = ordered_json::array();
    for (const auto& se : sentences) {
        ordered_json obj;
        if (se.nameType == NameType::Single) {
            obj["name"] = se.name_preview;
        }
        else if (se.nameType == NameType::Multiple) {
            obj["names"] = se.names_preview;
        }
        obj["message"] = se.translated_preview;
        if (m_outputWithSrc) {
            obj["src_msg"] = se.original_text;
        }
        outputJson.push_back(obj);
    }

    std::ofstream ofs(outputPath);
    ofs << outputJson.dump(2);
    ofs.close();

    m_logger->info("[线程 {}] [文件 {}] 处理完成。", threadId, wide2Ascii(relInputPath));
    m_controller->reduceThreadNum();

    if (m_needsCombining) {
        const fs::path& originalRelFilePath = m_splitFilePartsToJson[relInputPath];
        auto& splitFileParts = m_jsonToSplitFileParts[originalRelFilePath];
        {
            std::lock_guard<std::mutex> lock(m_outputMutex);
            splitFileParts[relInputPath] = true;
            if (
                std::ranges::any_of(splitFileParts, [](const auto& p) { return !p.second; })
                )
            {
                m_logger->debug("文件 {} 尚未全部处理完成，跳过合并。", wide2Ascii(originalRelFilePath));
                return;
            }
            m_logger->debug("开始合并 {} 的缓存文件...", wide2Ascii(originalRelFilePath));
        }
        combineOutputFiles(originalRelFilePath, splitFileParts, m_logger, m_outputCacheDir, m_outputDir);
        std::unique_lock<std::mutex> lock(m_outputMutex);
        if (m_pythonTranslator) {
            lock.unlock(); // 非常神奇
        }
        if (m_onFileProcessed) {
            m_onFileProcessed(originalRelFilePath);
        }
        m_logger->debug("[线程 {}] [文件 {}] 合并处理完成。", threadId, wide2Ascii(originalRelFilePath));
    }
    else {
        std::unique_lock<std::mutex> lock(m_outputMutex);
        if (m_pythonTranslator) {
            lock.unlock();
        }
        if (m_onFileProcessed) {
            m_onFileProcessed(relInputPath);
        }
    }
}

// ================================================         run           ========================================
std::optional<std::vector<fs::path>> NormalJsonTranslator::beforeRun() {

    if (fs::exists(m_cacheDir)) {
        std::error_code ec;
        fs::copy(m_cacheDir, m_cacheDir.parent_path() / L"transl_cache_bak", fs::copy_options::recursive | fs::copy_options::overwrite_existing, ec);
    }
    for (const auto& dir : { m_inputDir, m_outputDir, m_cacheDir }) {
        if (!fs::exists(dir)) {
            fs::create_directories(dir);
            m_logger->debug("已创建目录: {}", wide2Ascii(dir));
        }
    }

    // 所有的json相对路径
    std::vector<fs::path> relJsonPaths;

    std::ifstream ifs;
    std::ofstream ofs;

    // 人名表处理
    {
        std::map<std::string, int> nameTableMap;
        Sentence se;

        auto insertNameTable = [&](const std::string& name)
            {
                if (name.empty()) {
                    return;
                }
                nameTableMap[name]++;
            };

        // 收集人名和json相对路径，检查msg字段是否存在
        for (const auto& entry : fs::recursive_directory_iterator(m_inputDir)) {
            if (!entry.is_regular_file() || !isSameExtension(entry.path(), L".json")) {
                continue;
            }
            fs::path relInputPath = fs::relative(entry.path(), m_inputDir);
            relJsonPaths.push_back(relInputPath);
            try {
                ifs.open(entry.path());
                json data = json::parse(ifs);
                ifs.close();

                for (const auto& [index, item] : data | std::views::enumerate) {
                    m_totalSentences++;
                    if (item.contains("name")) {
                        se.name = item["name"].get<std::string>();
                        if (m_usePreDictInName) {
                            se.name = m_preDictionary.doReplace(&se, CachePart::Name);
                        }
                        insertNameTable(se.name);
                    }
                    else if (item.contains("names")) {
                        for (const auto& name : item["names"]) {
                            se.name = name.get<std::string>();
                            if (m_usePreDictInName) {
                                se.name = m_preDictionary.doReplace(&se, CachePart::Name);
                            }
                            insertNameTable(se.name);
                        }
                    }
                    if (!item.contains("message")) {
                        throw std::runtime_error(std::format("[文件 {}] 第 {} 个对象缺少 message 字段。", wide2Ascii(relInputPath), index));
                    }
                }
            }
            catch (const json::exception& e) {
                m_logger->critical("读取文件 {} 时出错", wide2Ascii(relInputPath));
                throw std::runtime_error(e.what());
            }
        }

        if (m_totalSentences == 0) {
            throw std::runtime_error("未找到有效的 Sentence");
        }
        m_controller->makeBar(m_totalSentences, m_threadsNum);


        const fs::path nameTablePath = m_projectDir / L"人名替换表.toml";
        toml::value orgNameTable = toml::table{};
        try {
            if (fs::exists(nameTablePath)) {
                orgNameTable = toml::parse(nameTablePath);
            }
        }
        catch (...) {
            m_logger->error("解析原人名表失败");
        }

        std::vector<std::pair<std::string, int>> nameTableKeys;
        for (const auto& nameCountPair : nameTableMap) {
            nameTableKeys.push_back(nameCountPair);
        }
        std::ranges::sort(nameTableKeys, [&](const auto& a, const auto& b)
            {
                if (a.second == b.second) {
                    return a.first.length() > b.first.length();
                }
                return a.second > b.second;
            });

        toml::ordered_value newNameTable = toml::ordered_table{};
        newNameTable.comments().push_back("'原名' = [ '译名', 出现次数 ]");
        for (const auto& key : nameTableKeys | std::views::keys) {
            try {
                newNameTable[key] = toml::array{ toml::find_or(orgNameTable, key, 0, ""), nameTableMap[key] };
            }
            catch (...) {
                newNameTable[key] = toml::array{ "", nameTableMap[key] };
            }
        }
        ofs.open(nameTablePath);
        ofs << toml::format(newNameTable);
        ofs.close();
        m_logger->info("已更新 人名替换表.toml 文件");
        if (m_transEngine == TransEngine::DumpName) {
            m_completedSentences += m_totalSentences;
            m_controller->updateBar(m_totalSentences);
            return std::nullopt;
        }
    }
    // 人名表处理完毕


    // 字典生成
    if (m_transEngine == TransEngine::GenDict) {
        auto preProcessFunc = [this](Sentence* se)
            {
                this->preProcess(se);
            };
        DictionaryGenerator generator(m_controller, m_logger, m_apiPool, m_tokenizeSourceLangFunc,
            preProcessFunc, m_systemPrompt, m_userPrompt, m_apiStrategy,
            m_maxRetries, m_threadsNum, m_apiTimeOutMs, m_checkQuota);
        fs::path outputFilePath = m_projectDir / L"项目GPT字典-生成.toml";
        std::vector<fs::path> inputPaths = std::move(relJsonPaths);
        for (auto& inputPath : inputPaths) {
            inputPath = m_inputDir / inputPath;
        }
        generator.generate(inputPaths, outputFilePath);
        return std::nullopt;
    }
    // 字典生成完毕


    // 解析人名替换表
    try {
        const auto nameTable = toml::parse(m_projectDir / L"人名替换表.toml");

        for (const auto& [key, value] : nameTable.as_table()) {
            if (!value.is_array() || value.size() == 0) {
                continue;
            }
            const std::string& transName = toml::find_or(value, 0, "");
            if (!transName.empty()) {
                m_logger->trace("发现原名 '{}' 的译名 '{}'", key, transName);
                m_nameMap.insert(std::make_pair(key, transName));
            }
        }
    }
    catch (const toml::exception& e) {
        m_logger->critical("解析 人名替换表.toml 时出错");
        throw std::runtime_error(e.what());
    }
    // 解析人名替换表完毕


    // 单文件分割
    {
        auto splitFunc = [&](std::function<std::vector<json>(const json&, int)> splitImplFunc)
            {
                if (m_splitFileNum <= 0) {
                    throw std::invalid_argument("文件分割数必须大于 0");
                }
                m_needsCombining = true;
                m_logger->info("检测到文件分割模式 ({})，开始预处理输入文件...", m_splitFile);
                for (const auto& relJsonPath : relJsonPaths) {
                    try {
                        ifs.open(m_inputDir / relJsonPath);
                        json data = json::parse(ifs);
                        ifs.close();
                        const std::vector<json>& parts = splitImplFunc(data, m_splitFileNum);
                        std::wstring relStem = relJsonPath.parent_path() / relJsonPath.stem();
                        for (size_t i = 0; i < parts.size(); ++i) {
                            fs::path relPartPath = relStem + L"_part_" + std::to_wstring(i) + relJsonPath.extension().wstring();
                            m_splitFilePartsToJson[relPartPath] = relJsonPath;
                            m_jsonToSplitFileParts[relJsonPath].insert(std::make_pair(relPartPath, false));
                            fs::path partPath = m_inputCacheDir / relPartPath;
                            createParent(partPath);
                            ofs.open(partPath);
                            ofs << parts[i].dump(2);
                            ofs.close();
                        }
                        m_logger->debug("文件 {} 已被分割成 {} 份，存入输入缓存。", wide2Ascii(relJsonPath), parts.size());

                    }
                    catch (const json::exception& e) {
                        m_logger->critical("分割文件 {} 时出错", wide2Ascii(relJsonPath));
                        throw std::runtime_error(e.what());
                    }
                }
            };
        if (m_splitFile == "Equal") {
            splitFunc(splitJsonArrayEqual);
        }
        else if (m_splitFile == "Num") {
            splitFunc(splitJsonArrayNum);
        }
        else if (m_splitFile != "No") {
            throw std::invalid_argument(std::format("未知的文件分割模式: {}, 请使用 'No', 'Equal', 'Num'", m_splitFile));
        }
    }
    // 单文件分割完毕

    // 分发文件
    std::vector<fs::path> relFilePaths;
    if (!m_needsCombining) {
        relFilePaths = std::move(relJsonPaths);
    }
    else {
        for (const auto& relPartPath : m_splitFilePartsToJson | std::views::keys) {
            relFilePaths.push_back(relPartPath);
        }
    }
    if (relFilePaths.empty()) {
        throw std::runtime_error("未找到任何待翻译文件。");
    }

    if (m_sortMethod == "size") {
        std::ranges::sort(relFilePaths, [&](const fs::path& a, const fs::path& b)
            {
                return m_needsCombining ? (fs::file_size(m_inputCacheDir / a) > fs::file_size(m_inputCacheDir / b)) :
                    (fs::file_size(m_inputDir / a) > fs::file_size(m_inputDir / b));
            });
    }
    else if (m_sortMethod == "name") {
        std::ranges::sort(relFilePaths);
    }
    else {
        throw std::invalid_argument(std::format("未知的排序模式: {}", m_sortMethod));
    }
    return relFilePaths;
}

void NormalJsonTranslator::afterRun() {
    // 问题概览
    if (m_problemOverview.as_array().empty()) {
        m_logger->info("\n\n```\n无问题概览\n```\n");
    }
    else {
        std::ofstream ofs;
        ofs.open(m_projectDir / L"翻译问题概览.toml");
        ofs << toml::format("problemOverview", m_problemOverview);
        ofs.close();
        ofs.open(m_projectDir / L"翻译问题概览.json");
        ofs << toml2Json(m_problemOverview).dump(2);
        ofs.close();
        m_logger->debug("已生成 翻译问题概览.json 和 翻译问题概览.toml 文件");

        std::map<std::string, std::set<std::string>> problemMap;
        for (const auto& [problem, filename] : m_problemOverview.as_array()
            | std::views::transform([](const auto& tbl)
                {
                    const auto& problemsArr = tbl.at("problems").as_array();
                    const auto problemsWithFileNameView = problemsArr | std::views::transform([&](const auto& prob)
                        {
                            return std::make_pair(prob.as_string(), tbl.at("filename").as_string());
                        });
                    return problemsWithFileNameView;
                }) | std::views::join)
        {
            problemMap[problem].insert(filename);
        }

        std::string problemOverviewStr = "\n\n```\n问题概览:\n";
        size_t problemCount = 0;
        for (const auto& [problem, files] : problemMap) {
            std::string fileStr = "(";
            size_t fileCount = 0;
            for (const auto& file : files) {
                if (fileCount == 3) {
                    break;
                }
                fileStr += file + ", ";
                fileCount++;
            }
            if (fileCount == files.size()) {
                fileStr.pop_back();
                fileStr.pop_back();
                fileStr += ")";
            }
            else {
                fileStr += "...)";
            }
            problemOverviewStr += std::format("{}. {}  |  {}\n", ++problemCount, problem, fileStr);
        }
        m_logger->error("{}问题概览结束\n```\n", problemOverviewStr);
    }
    // 问题概览完毕

    if (m_needsCombining) {
        fs::remove_all(m_inputCacheDir);
        fs::remove_all(m_outputCacheDir);
    }
    if (!m_controller->shouldStop() && m_transEngine == TransEngine::Rebuild && m_completedSentences != m_totalSentences) {
        m_logger->critical("重建过程中有句子未命中缓存 ({}/{} lines)，请检查日志以定位问题。", m_completedSentences.load(), m_totalSentences);
    }
    m_logger->info("Plugin time cost: {}ms", m_pluginTimeUsed.load() / 1000 / 1000);
}

void NormalJsonTranslator::process(std::vector<fs::path> relFilePaths) {
    std::vector<std::future<void>> results;
    m_threadPool.resize(std::min(m_threadsNum, (int)relFilePaths.size()));
    for (const auto& filePath : relFilePaths) {
        results.emplace_back(m_threadPool.push([=](const int id)
            {
                this->processFile(filePath, id);
            }));
    }
    m_logger->info("已将 {} 个文件任务分配到线程池，等待处理完成...", results.size());
    for (auto& result : results) {
        result.get();
    }
}

void NormalJsonTranslator::run() {
    NormalJsonTranslator::init();
    std::optional<std::vector<fs::path>> relFilePathsOpt = NormalJsonTranslator::beforeRun();
    if (!relFilePathsOpt.has_value()) {
        return;
    }
    NormalJsonTranslator::process(std::move(relFilePathsOpt.value()));
    NormalJsonTranslator::afterRun();
}
