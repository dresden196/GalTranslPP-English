[plugins.TextLinebreakFix]
"换行模式" = "优先标点"   # [优先标点|保持位置|平均|固定字数]
"优先阈值" = 0.2       # 仅在 优先标点 模式有效，值越高，换行的相对位置的可以变动以去匹配标点的限度就越大
"分段字数阈值" = 21      # 仅在 固定字数 模式有效
"强制修复" = false
"报错阈值" = 28        # 某一行字数超过此值将会添加进problem

"使用分词器" = false   # 可能可以获得更好的换行效果(不过感觉用处不大)
tokenizerBackend = "MeCab" # MeCab, spaCy, Stanza (除了MeCab，剩下的都依赖Python，自动安装需重启程序)
# 填目标语言的模型/字典
# mecab-chinese 下载地址:
# https://github.com/panyang/MeCab-Chinese/tree/master/data/v0.3 或
# https://github.com/ueda-keisuke/CC-CEDICT-MeCab
mecabDictDir = "BaseConfig/mecabDict/mecab-chinese" 
# https://spacy.io/models
spaCyModelName = "zh_core_web_trf"
# https://stanfordnlp.github.io/stanza/ner_models.html
stanzaLang = "zh"